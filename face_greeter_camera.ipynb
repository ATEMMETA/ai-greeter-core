{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Face Greeter: Real-Time Video Analytics System\n",
        "\n",
        "This Jupyter Notebook powers the backend for FaceGreeter, a real-time video analytics system for businesses. It uses `face_recognition` for face detection, OpenCV for video processing, and a Flask API to manage camera connections, video streaming, and customer insights via the xAI Grok API. The system integrates with the Vercel frontend at `https://facegreeter.vercel.app`.\n",
        "\n",
        "## Prerequisites\n",
        "- Google Colab environment with internet access.\n",
        "- `NGROK_AUTHTOKEN` and `GROK_API_KEY` stored in Colab Secrets.\n",
        "- Camera at `192.168.100.47` accessible on the local network.\n",
        "- Vercel frontend deployed at `https://facegreeter.vercel.app`.\n",
        "\n",
        "## Steps\n",
        "1. Install dependencies.\n",
        "2. Set up environment variables.\n",
        "3. Run Flask API with ngrok.\n",
        "4. Test camera connection and video analytics.\n",
        "\n",
        "**Security Note**: Securely handle `NGROK_AUTHTOKEN`, `GROK_API_KEY`, and camera credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install flask==3.0.3 opencv-python==4.9.0.80 face-recognition==1.3.0 numpy==2.0.2 pyngrok==7.1.6 python-dotenv==1.0.1 requests==2.32.3 flask-cors==5.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up environment variables\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "with open('/content/.env', 'w') as f:\n",
        "    f.write(f'NGROK_AUTHTOKEN={userdata.get(\"NGROK_AUTHTOKEN\")}\\n')\n",
        "    f.write('V380_RTSP_URL=rtsp://admin:12345@192.168.100.47:554/live/ch00_0\\n')\n",
        "    f.write('VERCEL_URL=https://facegreeter.vercel.app\\n')\n",
        "    f.write('VERCEL_API_BASE_URL=https://facegreeter.vercel.app\\n')\n",
        "    f.write(f'GROK_API_KEY={userdata.get(\"GROK_API_KEY\")}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write Flask application\n",
        "%%writefile /content/combined_app.py\n",
        "import cv2\n",
        "import face_recognition\n",
        "import numpy as np\n",
        "import os\n",
        "import logging\n",
        "from flask import Flask, request, jsonify, Response\n",
        "from flask_cors import CORS\n",
        "from dotenv import load_dotenv\n",
        "import requests\n",
        "import base64\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app, resources={r\"/*\": {\"origins\": \"https://facegreeter.vercel.app\"}})\n",
        "load_dotenv()\n",
        "\n",
        "GROK_API_KEY = os.getenv(\"GROK_API_KEY\")\n",
        "images_path = \"/content/images\"\n",
        "os.makedirs(images_path, exist_ok=True)\n",
        "known_face_encodings = {}\n",
        "for fname in os.listdir(images_path):\n",
        "    if fname.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "        name = os.path.splitext(fname)[0]\n",
        "        image_path = os.path.join(images_path, fname)\n",
        "        image = face_recognition.load_image_file(image_path)\n",
        "        encodings = face_recognition.face_encodings(image)\n",
        "        if encodings:\n",
        "            known_face_encodings[name] = encodings[0]\n",
        "\n",
        "connected_cameras = {}\n",
        "\n",
        "@app.route('/connect_camera', methods=['POST'])\n",
        "def connect_camera():\n",
        "    try:\n",
        "        data = request.json\n",
        "        ip = data.get('ip')\n",
        "        username = data.get('username', 'admin')\n",
        "        password = data.get('password', '12345')\n",
        "        wifi_ssid = data.get('wifi_ssid', '')\n",
        "        wifi_password = data.get('wifi_password', '')\n",
        "        logger.info(f\"Attempting to connect to camera at {ip}\")\n",
        "\n",
        "        import re\n",
        "        if not re.match(r\"^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$\", ip):\n",
        "            return jsonify({\"success\": False, \"error\": \"Invalid IP address\"}), 400\n",
        "\n",
        "        rtsp_url = f\"rtsp://{username}:{password}@{ip}:554/live/ch00_0\"\n",
        "        cap = cv2.VideoCapture(rtsp_url)\n",
        "        if not cap.isOpened():\n",
        "            logger.warning(f\"Failed to connect to camera at {ip}\")\n",
        "            return jsonify({\"success\": False, \"error\": \"Failed to connect to camera\"}), 400\n",
        "        cap.release()\n",
        "\n",
        "        if wifi_ssid and wifi_password:\n",
        "            try:\n",
        "                wifi_response = requests.post(\n",
        "                    f\"http://{ip}/set_wifi\",\n",
        "                    data={\"ssid\": wifi_ssid, \"password\": wifi_password},\n",
        "                    timeout=5\n",
        "                )\n",
        "                if wifi_response.status_code != 200:\n",
        "                    logger.warning(f\"Failed to configure Wi-Fi for {ip}\")\n",
        "            except requests.RequestException as e:\n",
        "                logger.error(f\"Wi-Fi configuration error: {str(e)}\")\n",
        "\n",
        "        connected_cameras[ip] = rtsp_url\n",
        "        logger.info(f\"Successfully connected to camera at {ip}\")\n",
        "\n",
        "        vercel_url = os.getenv(\"VERCEL_API_BASE_URL\", \"https://facegreeter.vercel.app\")\n",
        "        requests.post(\n",
        "            f\"{vercel_url}/api/camera_connected\",\n",
        "            json={\"ip\": ip, \"rtsp_url\": rtsp_url, \"model\": \"V380\"}\n",
        "        )\n",
        "\n",
        "        return jsonify({\"success\": True, \"rtsp_url\": rtsp_url, \"error\": None})\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error connecting to camera: {str(e)}\")\n",
        "        return jsonify({\"success\": False, \"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/video_feed', methods=['GET'])\n",
        "def video_feed():\n",
        "    try:\n",
        "        rtsp_url = request.args.get('rtsp')\n",
        "        if not rtsp_url or rtsp_url not in connected_cameras.values():\n",
        "            return jsonify({\"success\": False, \"error\": \"Invalid or unconnected camera\"}), 400\n",
        "\n",
        "        cap = cv2.VideoCapture(rtsp_url)\n",
        "        if not cap.isOpened():\n",
        "            return jsonify({\"success\": False, \"error\": \"Failed to open camera stream\"}), 500\n",
        "\n",
        "        def generate():\n",
        "            prev_frame = None\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    logger.warning(\"Failed to capture frame\")\n",
        "                    break\n",
        "                frame = cv2.resize(frame, (640, 480))\n",
        "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "                if prev_frame is not None:\n",
        "                    diff = cv2.absdiff(gray, prev_frame)\n",
        "                    motion = np.mean(diff) > 5\n",
        "                    if motion:\n",
        "                        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                        face_locations = face_recognition.face_locations(frame_rgb)\n",
        "                        face_encodings = face_recognition.face_encodings(frame_rgb, face_locations)\n",
        "                        for (top, right, bottom, left), encoding in zip(face_locations, face_encodings):\n",
        "                            name = \"Unknown\"\n",
        "                            matches = face_recognition.compare_faces(list(known_face_encodings.values()), encoding)\n",
        "                            if True in matches:\n",
        "                                first_match_index = matches.index(True)\n",
        "                                name = list(known_face_encodings.keys())[first_match_index]\n",
        "                            color = (0, 0, 255) if name == \"Unknown\" else (0, 255, 0)\n",
        "                            cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_DUPLEX, 1, color, 1)\n",
        "                            cv2.rectangle(frame, (left, top), (right, bottom), color, 1)\n",
        "                        ret, buffer = cv2.imencode(\".jpg\", frame)\n",
        "                        yield (b\"--frame\\r\\n\"\n",
        "                               b\"Content-Type: image/jpeg\\r\\n\\r\\n\" + buffer.tobytes() + b\"\\r\\n\")\n",
        "                prev_frame = gray\n",
        "            cap.release()\n",
        "\n",
        "        return Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error streaming video: {str(e)}\")\n",
        "        return jsonify({\"success\": False, \"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/detect_face', methods=['POST'])\n",
        "def detect_face():\n",
        "    try:\n",
        "        data = request.json\n",
        "        rtsp_url = data.get('rtsp_url')\n",
        "        if not rtsp_url or rtsp_url not in connected_cameras.values():\n",
        "            return jsonify({\"success\": False, \"error\": \"Invalid or unconnected RTSP URL\"}), 400\n",
        "\n",
        "        logger.info(f\"Detecting faces for RTSP: {rtsp_url}\")\n",
        "        cap = cv2.VideoCapture(rtsp_url)\n",
        "        if not cap.isOpened():\n",
        "            return jsonify({\"success\": False, \"error\": \"Failed to open camera stream\"}), 500\n",
        "\n",
        "        ret, frame = cap.read()\n",
        "        cap.release()\n",
        "        if not ret:\n",
        "            return jsonify({\"success\": False, \"error\": \"Failed to capture frame\"}), 500\n",
        "\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        face_locations = face_recognition.face_locations(frame_rgb)\n",
        "        face_encodings = face_recognition.face_encodings(frame_rgb, face_locations)\n",
        "        face_names = []\n",
        "        for encoding in face_encodings:\n",
        "            name = \"Unknown\"\n",
        "            matches = face_recognition.compare_faces(list(known_face_encodings.values()), encoding)\n",
        "            if True in matches:\n",
        "                first_match_index = matches.index(True)\n",
        "                name = list(known_face_encodings.keys())[first_match_index]\n",
        "            face_names.append(name)\n",
        "        logger.info(f\"Detected {len(face_names)} faces\")\n",
        "        return jsonify({\"success\": True, \"locations\": face_locations, \"names\": face_names})\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error detecting face: {str(e)}\")\n",
        "        return jsonify({\"success\": False, \"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/customer_insights', methods=['POST'])\n",
        "def customer_insights():\n",
        "    try:\n",
        "        data = request.json\n",
        "        face_names = data.get('face_names', [])\n",
        "        logger.info(f\"Processing customer insights for faces: {face_names}\")\n",
        "\n",
        "        insights = []\n",
        "        for name in face_names:\n",
        "            prompt = f\"Greet {name} warmly as a returning customer.\" if name != \"Unknown\" else \"Greet an unknown visitor politely and offer assistance.\"\n",
        "            try:\n",
        "                response = requests.post(\n",
        "                    \"https://api.x.ai/v1/chat/completions\",\n",
        "                    headers={\"Authorization\": f\"Bearer {GROK_API_KEY}\"},\n",
        "                    json={\"model\": \"grok-3\", \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"max_tokens\": 100},\n",
        "                )\n",
        "                response.raise_for_status()\n",
        "                reply = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "                insights.append({\n",
        "                    \"name\": name,\n",
        "                    \"status\": \"Returning customer\" if name != \"Unknown\" else \"New visitor\",\n",
        "                    \"greeting\": reply\n",
        "                })\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Grok API error for {name}: {str(e)}\")\n",
        "                insights.append({\n",
        "                    \"name\": name,\n",
        "                    \"status\": \"Error\",\n",
        "                    \"greeting\": f\"Welcome{' back, ' + name if name != 'Unknown' else '!'}\"\n",
        "                })\n",
        "\n",
        "        return jsonify({\"success\": True, \"insights\": insights})\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating customer insights: {str(e)}\")\n",
        "        return jsonify({\"success\": False, \"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/add_face', methods=['POST'])\n",
        "def add_face():\n",
        "    try:\n",
        "        data = request.json\n",
        "        name = data.get('name')\n",
        "        image_data = data.get('image_data')\n",
        "        if not name or not image_data:\n",
        "            return jsonify({\"success\": False, \"error\": \"Missing name or image data\"}), 400\n",
        "\n",
        "        image_array = cv2.imdecode(np.frombuffer(base64.b64decode(image_data), np.uint8), cv2.IMREAD_COLOR)\n",
        "        frame_rgb = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
        "        encodings = face_recognition.face_encodings(frame_rgb)\n",
        "        if not encodings:\n",
        "            return jsonify({\"success\": False, \"error\": \"No face detected\"}), 400\n",
        "\n",
        "        image_path = os.path.join(images_path, f\"{name}.jpg\")\n",
        "        cv2.imwrite(image_path, image_array)\n",
        "        known_face_encodings[name] = encodings[0]\n",
        "        logger.info(f\"Added face for {name}\")\n",
        "        return jsonify({\"success\": True, \"error\": None})\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error adding face: {str(e)}\")\n",
        "        return jsonify({\"success\": False, \"error\": str(e)}), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=8000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run Flask with ngrok\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "os.system('pkill ngrok')\n",
        "public_url = ngrok.connect(8000).public_url\n",
        "print(f'Flask API available at: {public_url}')\n",
        "os.system('python /content/combined_app.py &')\n",
        "\n",
        "# Keep the notebook running\n",
        "input('Press Enter to stop the Flask server...')\n"
      ]
    }
  ]
}
